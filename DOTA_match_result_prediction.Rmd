---
title: "Predicting DOTA match results"
output: html_notebook
---

https://www.kaggle.com/devinanzelmo/d/devinanzelmo/dota-2-matches/setting-up-a-prediction-problem-dota-2


# Background
TODO: What is DOTA, how to play, Radiant vs Dire.

# Goal
The goal of this experiment is to find a model that could estimate the outcome of a DOTA 2 match based only on the participating players and their stats/history.

# Data

## Get
Data was downloaded from https://www.kaggle.com/devinanzelmo/dota-2-matches
TODO: how to download / where to extract

## Explore
```{r, message=FALSE}
library(readr)
library(data.table)
library(reshape2)
library(dplyr)
library(h2o)
localH2O = h2o.init(nthreads=-1)
```

### match.csv variables
Match contains all the high level statistics of the match like the status of the towers at the end of the match and more importantly the outcome. Most if these variables should be dropped because most of them are not available before the matches.

The few exceptions:

**game_mode:**
```{r, message=FALSE}
match <- data.table(read_csv("data/match.csv"))
nrow(match)
match[, .N, by=game_mode]
```
The two possible values for *game_mode* are the same from the aspect of game mechanics. Both (2-Captain Mode, 22-Ranked Matchmaking) are consists of a *banning phase* followed by *all pick* --> Feature will be removed. 

**start_time:**
It is irrelevant --> Will be removed.

**radiant_win:**
Indicates whether the *Radiant* or the *Dire* team won the match. It will be converted to a binary variable: 1-Radiant, 0-Dire win.

**match_id:** should be kept to identify the match.

Finalize match outcome df:
```{r, message=FALSE}
# Training outcome
match <- match[, list(match_id,radiant_win)]
match[, winner:= as.factor(if_else(radiant_win == "True", true = "RADIANT", false = "DIRE"))]
match$radiant_win <- NULL
ranked_match_outcome_train <- match
rm(match)

# Test outcome
ranked_match_outcome_test <- data.table(read_csv("data/test_labels.csv"))
ranked_match_outcome_test[, winner:=as.factor(if_else(radiant_win == 1, true = "RADIANT", false = "DIRE"))]
ranked_match_outcome_test$radiant_win <- NULL
```

### player_rating.csv variables
```{r, message=FALSE}
legacy_player_ratings <- data.table(read_csv("data/player_ratings.csv"))
nrow(legacy_player_ratings)
```

# Exp1
Average player winrate.

```{r, message=FALSE}
# Player ratings can be calculated from 900K historical matches
legacy_player_ratings[, win_percent:=total_wins/total_matches]
```

```{r, message=FALSE}
# Imputing missing data: if there is no stat for the player, lets asume he is an average player (id 0 is for the average)
unidentified_win_percent <- legacy_player_ratings[account_id==0, win_percent]

# Each row represents a player in a match thus 10 rows represents a match
players_train <- data.table(read_csv("data/players.csv"))
players_test <- data.table(read_csv("data/test_player.csv"))

feature1 <- function(legacy_player_ratings, players, outcome, imputed_win_percent) {
  playerdata <- data.table(left_join(players, legacy_player_ratings[, c("account_id", "win_percent")],
                          by=c("account_id" = "account_id")))
  playerdata[is.na(win_percent), win_percent:=unidentified_win_percent]
  
  # player_slot 0-4: radiant, 128-132: dire
  playerdata[, side:= as.factor(if_else(player_slot < 100, true = "RADIANT", false = "DIRE"))]
  
  teamstat <- playerdata%>% group_by(match_id, side) %>% summarise(win_percent_legacy=mean(win_percent))
  teamstat <- left_join(teamstat[teamstat$side == "RADIANT", c("match_id", "win_percent_legacy")],
                  teamstat[teamstat$side == "DIRE", c("match_id", "win_percent_legacy")],
                  by="match_id", suffix=c("_RADIANT", "_DIRE"))
  out <- left_join(outcome, teamstat, by="match_id")
  
  return(out)
}

train <- feature1(legacy_player_ratings, players_train, ranked_match_outcome_train, unidentified_win_percent)
test <- feature1(legacy_player_ratings, players_test, ranked_match_outcome_test, unidentified_win_percent)

```


Try to do the analysis

```{r, message=FALSE}
upload_data <- function(up_train, up_test) {
  if(exists("h_train")) {
    h2o.rm(h_train)
  }
  if(exists("h_test")) {
    h2o.rm(h_test)
  }
  h_train <<- as.h2o(up_train)
  h_test <<- as.h2o(up_test)
}

upload_data(train, test)

linear_model <- h2o.glm(x = c("win_percent_legacy_RADIANT", "win_percent_legacy_DIRE"), y = "winner",
                  training_frame = h_train, validation_frame = h_test,
                  family = "binomial",
                  score_each_iteration = TRUE)

h2o.auc(linear_model)
plot(h2o.performance(linear_model, valid = TRUE))

h2o.confusionMatrix(linear_model, newdata = h_test)
```

Ok. It is only a slight better than pure guessing.
From my own playing experience I know that in this game playing more matches are very important. Adding this kind of information as a feature may have a positive effect on the guessing.

```{r}
# In player ratings for account 0 (all of unidentified accounts) the number of matches are not for one player but all of the unidentified players. Also there are missing values. This will be corrected to use an average.

avg_legacy_match_count <- as.integer(round(mean(as.numeric(player_ratings[player_ratings$account_id != 0, "total_matches"]$total_matches))))
player_ratings[player_ratings$account_id == 0 | is.na(player_ratings$account_id), "total_matches"] <- avg_legacy_match_count

playerdata <- data.table(left_join(playerdata, player_ratings[,.(account_id, total_matches)], by = "account_id"))
playerdata[is.na(total_matches), total_matches:=avg_legacy_match_count]

teamstat <- playerdata %>% group_by(match_id, side) %>% summarise(win_percent_legacy=mean(win_percent_legacy), avg_matches_legacy=mean(total_matches), total_matches_legacy=sum(total_matches))

teamstat_join_columns <- c("match_id", "win_percent_legacy", "avg_matches_legacy", "total_matches_legacy")
teamstat <- left_join(teamstat[teamstat$side == "RADIANT", teamstat_join_columns],
                teamstat[teamstat$side == "DIRE", teamstat_join_columns],
                by="match_id", suffix=c("_RADIANT", "_DIRE")
)

matchdata <- left_join(match_outcome, teamstat, by="match_id")


set.seed(123)

train_indices <- sample(1:nrow(dataset), 0.9 * nrow(dataset))
train <- matchdata[train_indices,]
test <- matchdata[-train_indices,]

upload_data(train, test)

linear_model <- h2o.glm(x = c(
  "win_percent_legacy_RADIANT",
  "win_percent_legacy_DIRE",
  "avg_matches_legacy_RADIANT",
  "avg_matches_legacy_DIRE",
  "total_matches_legacy_RADIANT",
  "total_matches_legacy_DIRE"),
  y = "winner",
  training_frame = h_train, validation_frame = h_test,
  family = "binomial",
  score_each_iteration = TRUE)

h2o.auc(linear_model)
plot(h2o.performance(linear_model, valid = TRUE))

h2o.confusionMatrix(linear_model, newdata = h_test)
```

There is a slight improvement in the prediction accuracy. The conjecture was right.

Kill death ratio is also a very important statistics that shows the players skill. It can be calculated from the ranked match data. Of course it is not enough alone to determine player skill because some characters simply just better at doing the killing blow. Avg xp per minute and avg gold per minute also important.

```{r}
player_stat_rated <- playerdata %>% group_by(account_id) %>% summarise(kdr=sum(kills)/sum(deaths), avg_xp_per_min=mean(xp_per_min), avg_gold_per_min=mean(gold_per_min))

```




Actually the real game begins at character selection. A good combination of the heroes can lead to victory even for weaker players too. All the heroes will be added as a binary indicator variable.

```{r, message=FALSE}
hero_names <- data.table(read_csv("data/hero_names.csv"))

```
.
.
.
.
.
.
.
.