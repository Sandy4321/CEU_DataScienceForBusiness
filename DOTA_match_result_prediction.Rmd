---
title: "Predicting DOTA match results"
output:
  html_notebook: default
  html_document: default
---

https://www.kaggle.com/devinanzelmo/d/devinanzelmo/dota-2-matches/setting-up-a-prediction-problem-dota-2


# Background
TODO: What is DOTA, how to play, Radiant vs Dire.

# Goal
The goal of this experiment is to find a model that could estimate the outcome of a DOTA 2 match based only on the participating players and their stats/history.

# Data

## Get
Data was downloaded from https://www.kaggle.com/devinanzelmo/dota-2-matches
TODO: how to download / where to extract

## Explore
```{r, message=T}
library(readr)
library(data.table)
library(reshape2)
library(dplyr)
library(h2o)
library(ggplot2)

localH2O = h2o.init(nthreads=-1)
```

### match.csv variables
Match contains all the high level statistics of the match like the status of the towers at the end of the match and more importantly the outcome. Most if these variables should be dropped because most of them are not available before the matches.

The few exceptions:

**game_mode:**
```{r, message=FALSE}
match <- data.table(read_csv("data/match.csv"))
nrow(match)
match[, .N, by=game_mode]
```
The two possible values for *game_mode* are the same from the aspect of game mechanics. Both (2-Captain Mode, 22-Ranked Matchmaking) are consists of a *banning phase* followed by *all pick* --> Feature will be removed. 

**start_time:**
It is irrelevant --> Will be removed.

**radiant_win:**
Indicates whether the *Radiant* or the *Dire* team won the match. It will be converted to a binary variable: 1-Radiant, 0-Dire win.

**match_id:** should be kept to identify the match.

Finalize match outcome df:
```{r, message=FALSE}
# Training outcome
match <- match[, list(match_id,radiant_win)]
match[, winner:= as.factor(if_else(radiant_win == "True", true = "RADIANT", false = "DIRE"))]
match$radiant_win <- NULL
ranked_match_outcome_train <- match
rm(match)

# Test outcome
ranked_match_outcome_test <- data.table(read_csv("data/test_labels.csv"))
ranked_match_outcome_test[, winner:=as.factor(if_else(radiant_win == 1, true = "RADIANT", false = "DIRE"))]
ranked_match_outcome_test$radiant_win <- NULL
```

### player_rating.csv variables
```{r, message=FALSE}
legacy_player_ratings <- data.table(read_csv("data/player_ratings.csv"))
nrow(legacy_player_ratings)
```

# Exp1
Average player winrate.

```{r, message=FALSE}
# Player ratings can be calculated from 900K historical matches
legacy_player_ratings[, win_percent:=total_wins/total_matches]
```

```{r, message=FALSE}
# Imputing missing data: if there is no stat for the player, lets asume he is an average player (id 0 is for the average)
unidentified_win_percent <- legacy_player_ratings[account_id==0, win_percent]

# Each row represents a player in a match thus 10 rows represents a match
players_train <- data.table(read_csv("data/players.csv"))
players_test <- data.table(read_csv("data/test_player.csv"))

feature1 <- function(legacy_player_ratings, players, outcome, imputed_win_percent) {
  playerdata <- data.table(left_join(players, legacy_player_ratings[, c("account_id", "win_percent")],
                          by=c("account_id" = "account_id")))
  playerdata[is.na(win_percent), win_percent:=unidentified_win_percent]
  
  # player_slot 0-4: radiant, 128-132: dire
  playerdata[, side:= as.factor(if_else(player_slot < 100, true = "RADIANT", false = "DIRE"))]
  
  teamstat <- playerdata%>% group_by(match_id, side) %>% summarise(win_percent_legacy=mean(win_percent))
  teamstat <- left_join(teamstat[teamstat$side == "RADIANT", c("match_id", "win_percent_legacy")],
                  teamstat[teamstat$side == "DIRE", c("match_id", "win_percent_legacy")],
                  by="match_id", suffix=c("_RADIANT", "_DIRE"))
  out <- left_join(outcome, teamstat, by="match_id")
  
  return(out)
}
```

```{r, message=FALSE, results="hide"}
train <- feature1(legacy_player_ratings, players_train, ranked_match_outcome_train, unidentified_win_percent)
test <- feature1(legacy_player_ratings, players_test, ranked_match_outcome_test, unidentified_win_percent)

```


Try to do the analysis

```{r, message=FALSE}
upload_data <- function(up_train, up_test) {
  if(exists("h_train")) {
    h2o.rm(h_train)
  }
  if(exists("h_test")) {
    h2o.rm(h_test)
  }
  h_train <<- as.h2o(up_train)
  h_test <<- as.h2o(up_test)
}

upload_data(train, test)

linear_model <- h2o.glm(x = c("win_percent_legacy_RADIANT", "win_percent_legacy_DIRE"), y = "winner",
                  training_frame = h_train, validation_frame = h_test,
                  family = "binomial",
                  score_each_iteration = TRUE)

model_performance <- function(model) {
  auc <- h2o.auc(model, valid = TRUE)
  fpr <- h2o.fpr( h2o.performance(model, valid = TRUE) )[['fpr']]
  tpr <- h2o.tpr( h2o.performance(model, valid = TRUE) )[['tpr']]
  ggplot( data.table(fpr = fpr, tpr = tpr), aes(fpr, tpr) ) + 
    # geom_area(fill="#FCEBED") +
    geom_line(colour="red", size = 1) +
    geom_abline(linetype="dashed") +
    theme_bw() +
    ggtitle( sprintf('AUC: %f', auc) )
}

model_performance(linear_model)

h2o.confusionMatrix(linear_model, newdata = h_test)
```

Ok. It is only a slight better than pure guessing.
From my own playing experience I know that in this game playing more matches are very important. Adding this kind of information as a feature may have a positive effect on the guessing.

# Exp2
TODO: Distribution of match counts

```{r}
# In player ratings for account 0 (all of unidentified accounts) the number of matches are not for one player but all of the unidentified players. Also there are missing values. This will be corrected to use an average.
avg_legacy_match_count <- as.integer(round(mean(as.numeric(legacy_player_ratings[legacy_player_ratings$account_id != 0, "total_matches"]$total_matches))))
legacy_player_ratings[legacy_player_ratings$account_id == 0 | is.na(legacy_player_ratings$account_id), "total_matches"] <- avg_legacy_match_count

feature2 <- function(legacy_player_ratings, players, feature1, avg_legacy_match_count) {
  playerdata <- data.table(left_join(players_train, legacy_player_ratings[,.(account_id, total_matches)], by = "account_id"))
  playerdata[is.na(total_matches), total_matches:=avg_legacy_match_count]
  
  # player_slot 0-4: radiant, 128-132: dire
  playerdata[, side:= as.factor(if_else(player_slot < 100, true = "RADIANT", false = "DIRE"))]
  
  teamstat <- playerdata %>% group_by(match_id, side) %>% summarise(ln_avg_matches_legacy=log(mean(total_matches)), ln_total_matches_legacy=log(sum(total_matches)))
  
  teamstat_join_columns <- c("match_id", "ln_avg_matches_legacy", "ln_total_matches_legacy")
  teamstat <- left_join(teamstat[teamstat$side == "RADIANT", teamstat_join_columns],
                  teamstat[teamstat$side == "DIRE", teamstat_join_columns],
                  by="match_id", suffix=c("_RADIANT", "_DIRE")
              )
  out <- left_join(feature1, teamstat, by="match_id")
  
  return(out)
}

train <- feature2(legacy_player_ratings, players_train, train, avg_legacy_match_count)
test <- feature2(legacy_player_ratings, players_test, test, avg_legacy_match_count)


upload_data(train, test)

linear_model <- h2o.glm(x = c(
  "win_percent_legacy_RADIANT",
  "win_percent_legacy_DIRE",
  "ln_avg_matches_legacy_RADIANT",
  "ln_avg_matches_legacy_DIRE",
  "ln_total_matches_legacy_RADIANT",
  "ln_total_matches_legacy_DIRE"),
  y = "winner",
  training_frame = h_train, validation_frame = h_test,
  family = "binomial",
  score_each_iteration = TRUE)

model_performance(linear_model)

h2o.confusionMatrix(linear_model, newdata = h_test)

```

Unfortunatelly the prediction accuracy didn't increase. We have to find new ways to improve the accuracy.

# Exp3
Actually the real game begins at character selection. A good combination of the heroes can lead to victory even for weaker players too. All the heroes will be added as a binary indicator variable. (Hero ids: [1, 113])

As the linear model starting to become more complicated a random forest model will be evaluated too.


```{r, message=FALSE}

feature3 <- function(players, feature2) {
  herodata <- players[, list(match_id, player_slot, hero_id)]
  melted <- melt(herodata, id.vars = c("match_id", "player_slot"))
  melted[, variable:=as.factor(paste(ifelse(player_slot < 100, "RADIANT", "DIRE"), "hero", value, sep = "_"))]
  melted[, value:=1]
  herodata <- dcast(melted, match_id ~ variable)

  out <- left_join(feature2, herodata, by="match_id")
  
  return(out)
}

train <- feature3(players_train, train)
test <- feature3(players_test, test)

upload_data(train, test)

linear_model <- h2o.glm(
  x = colnames(train)[3:length(colnames(train))],
  y = "winner",
  training_frame = h_train, validation_frame = h_test,
  family = "binomial",
  score_each_iteration = TRUE)

model_performance(linear_model)

h2o.confusionMatrix(linear_model, newdata = h_test)

random_forest <- h2o.randomForest(
  x = colnames(train)[3:length(colnames(train))],
  y = "winner",
  training_frame = h_train, validation_frame = h_test
  # score_each_iteration = TRUE
  )

model_performance(random_forest)

h2o.confusionMatrix(random_forest, newdata = h_test)

```

The theory was confirmed: Adding information of hero selection increased the AUX about 11 percantage points for linear model. Random forest didn't performed that well as the linear model but using the new features it was still better than the linear model previously.


# Exp4

The following player stats will be calculated from ranked match data to have a detailed information regardint the invidual player skill:

* Kill death ratio (kdr) : An important statistics that shows the players skill. Unfortunately only killing blows count as kills therefore this ratio will be adjusted by counting assists (when the player participated in the kill but an other palyer got the actual kill)

* Average XP/min : Higher value means that the player participated in fights more actively and by acquiring more experience points he could level up faster. Level adavantage is a decision maker between win/lose.

* Average Gold/min : Higher value means that the player was able to have more lat hits (That earns golds) or was able to destroy enemy structures. With more gold the player could buy more advanced items and this is improving his team's chance to win.

These player performance indicators will be assigned to the corresponding player slot instead using simple averages. As an expectation it will add better control for players with exceptional skills because this kind of players can carry the match and win it. As usual account_id 0 is for unidentified players. The average values of all unidentified players imputed here.

```{r}
player_stat_rated <- players_train %>% group_by(account_id) %>%
  summarise(kdr=(sum(kills)+sum(assists))/sum(deaths), avg_xp_per_min=mean(xp_per_min), avg_gold_per_min=mean(gold_per_min))

feature4 <- function(players, feature3) {
  herodata <- players[, list(match_id, player_slot, account_id)]
  melted <- melt(herodata, id.vars = c("match_id", "player_slot"))
  melted <- data.table(left_join(melted, player_stat_rated, by=c("value" = "account_id")))
  melted[, variable:=as.factor(paste(ifelse(player_slot < 100, "RADIANT", "DIRE"), "kdr", player_slot %% 128, sep = "_"))]
  melted$value <- melted$kdr
  herodata1 <- dcast(melted, match_id ~ variable)
  melted[, variable:=as.factor(paste(ifelse(player_slot < 100, "RADIANT", "DIRE"), "avg_xp_per_min", player_slot %% 128, sep = "_"))]
  melted$value <- melted$avg_xp_per_min
  herodata2 <- dcast(melted, match_id ~ variable)
  melted[, variable:=as.factor(paste(ifelse(player_slot < 100, "RADIANT", "DIRE"), "avg_gold_per_min", player_slot %% 128, sep = "_"))]
  melted$value <- melted$avg_gold_per_min
  herodata3 <- dcast(melted, match_id ~ variable)
  
  out <- left_join(herodata1, herodata2, by="match_id")
  out <- left_join(out, herodata3, by="match_id")
  
  return(out)
}

gkdjkhkgjhf
```



.
.
.
.
.
.
.